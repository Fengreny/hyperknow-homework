import json
import os
import google.generativeai as genai
from dotenv import load_dotenv

# ====================== åŠ è½½apikey======================
load_dotenv()


# åŠ ä¸Š transport='rest'
genai.configure(api_key=os.environ["GEMINI_API_KEY"], transport='rest')


# åˆå§‹åŒ–åŸºç¡€æ¨¡å‹
model = genai.GenerativeModel("gemini-3-pro-preview")


# ======================å·¥å…·å‡½æ•° ======================
def memory_load_function(subject: str):
    """è¯»å–memory.jsonï¼ŒæŸ¥è¯¢ç”¨æˆ·æŒ‡å®šç§‘ç›®çš„çŸ¥è¯†æ°´å¹³"""
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢ç§‘ç›®: {subject}")
    try:
        with open('memory.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        knowledge_levels = data.get("knowledge_levels", {})
        if subject.lower() in knowledge_levels:
            result = knowledge_levels[subject.lower()]
            return json.dumps(result, ensure_ascii=False)
        else:
            return json.dumps({"error": f"æœªæ‰¾åˆ° {subject} çš„è®°å¿†ä¿¡æ¯"}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": f"è¯»å–è®°å¿†æ–‡ä»¶å‡ºé”™: {str(e)}"}, ensure_ascii=False)


def select_files(query: str):
    """æ ¹æ®å…³é”®è¯æœç´¢æœ¬åœ°æ–‡ä»¶ï¼Œè¿”å›ç›¸å…³æ–‡ä»¶ååˆ—è¡¨"""
    print(f"ğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: {query}")
    found_files = []
    try:
        with open('file_metadata.json', 'r', encoding='utf-8') as f:
            file_data = json.load(f)
        for filename, info in file_data.items():
            content = info.get("content", "").lower()
            if query.lower() in content:
                found_files.append(filename)
        print(f"âœ… æ‰¾åˆ° {len(found_files)} ä¸ªç›¸å…³æ–‡ä»¶")
        return json.dumps(found_files, ensure_ascii=False)
    except FileNotFoundError:
        return json.dumps({"error": "æ‰¾ä¸åˆ° file_metadata.json æ–‡ä»¶"}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": f"æœç´¢æ–‡ä»¶å‡ºé”™: {str(e)}"}, ensure_ascii=False)


def reply_generator(file_titles: list, instruction: str):
    """æµå¼ç”Ÿæˆæœ€ç»ˆå›å¤"""
    print(f"\nğŸ“ æ­£åœ¨ç”Ÿæˆå›å¤ï¼Œå‚è€ƒæ–‡ä»¶: {file_titles}")
    context_content = ""
    try:
        with open('file_metadata.json', 'r', encoding='utf-8') as f:
            all_files_data = json.load(f)
        for title in file_titles:
            if title in all_files_data:
                file_text = all_files_data[title]['content']
                context_content += f"\n--- æ–‡ä»¶å: {title} ---\n{file_text}\n"
    except Exception as e:
        return json.dumps({"error": f"è¯»å–æ–‡ä»¶å†…å®¹å‡ºé”™: {str(e)}"}, ensure_ascii=False)

    # æ„å»ºPrompt
    final_prompt = f"""
    ã€è§’è‰²ã€‘å¤©æ–‡è¯¾åŠ©æ•™ï¼Œé€‚é…åˆå­¦è€…æ°´å¹³
    ã€æŒ‡ä»¤ã€‘{instruction}
    ã€å‚è€ƒèµ„æ–™ã€‘{context_content if context_content else "æ— "}
    ã€è¦æ±‚ã€‘åˆ†ç‚¹æ€»ç»“ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œé¿å…ä¸“ä¸šæœ¯è¯­ã€‚
    """

    # æµå¼è°ƒç”¨Gemini
    try:
        response = model.generate_content(final_prompt, stream=True)
        print("\nğŸ’¡ Gemini å›å¤: ", end="", flush=True)
        full_text = ""
        for chunk in response:
            if chunk.text:
                print(chunk.text, end="", flush=True)
                full_text += chunk.text
        print("\n")
        return json.dumps({"status": "success", "reply": full_text}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": f"è°ƒç”¨Geminiå‡ºé”™: {str(e)}"}, ensure_ascii=False)


# å·¥å…·æ˜ å°„ï¼ˆç”¨äºè§£æåæ‰§è¡Œï¼‰
TOOL_MAP = {
    "memory_load_function": memory_load_function,
    "select_files": select_files,
    "reply_generator": reply_generator
}


# ====================== æ ¸å¿ƒ Agent é€»è¾‘ ======================
class directorAgent:
    def __init__(self):
        # å¯åŠ¨å¯¹è¯ä¼šè¯ï¼ˆä¿å­˜ä¸Šä¸‹æ–‡ï¼‰
        self.chat_session = model.start_chat(history=[])

        # æ ¸å¿ƒ Promptï¼ˆå‘Šè¯‰æ¨¡å‹å¦‚ä½•è¾“å‡ºå‡½æ•°è°ƒç”¨æŒ‡ä»¤ï¼Œæ›¿ä»£ Schema çš„ä½œç”¨ï¼‰
        self.function_call_prompt = """
        ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹å‡½æ•°æ¥å®Œæˆç”¨æˆ·ä»»åŠ¡ï¼š
        1. å‡½æ•°åï¼šmemory_load_function
           ä½œç”¨ï¼šæŸ¥è¯¢ç”¨æˆ·æŒ‡å®šç§‘ç›®çš„çŸ¥è¯†æ°´å¹³
           å‚æ•°ï¼š{"subject": "ç§‘ç›®åï¼ˆå¦‚astronomyï¼‰"}
           è¿”å›ï¼šJSONå­—ç¬¦ä¸²

        2. å‡½æ•°åï¼šselect_files
           ä½œç”¨ï¼šæ ¹æ®å…³é”®è¯æœç´¢æœ¬åœ°å¤©æ–‡è¯¾PDFæ–‡ä»¶
           å‚æ•°ï¼š{"query": "æœç´¢å…³é”®è¯ï¼ˆå¦‚astronomyï¼‰"}
           è¿”å›ï¼šJSONå­—ç¬¦ä¸²

        3. å‡½æ•°åï¼šreply_generator
           ä½œç”¨ï¼šç”Ÿæˆæœ€ç»ˆå›å¤ï¼ˆå”¯ä¸€çš„å›å¤å·¥å…·ï¼‰
           å‚æ•°ï¼š{"file_titles": ["æ–‡ä»¶å1", "æ–‡ä»¶å2"], "instruction": "ç”ŸæˆæŒ‡ä»¤"}
           è¿”å›ï¼šJSONå­—ç¬¦ä¸²

        ä½ çš„è¾“å‡ºè§„åˆ™ï¼š
        - å¦‚æœéœ€è¦è°ƒç”¨å‡½æ•°ï¼Œè¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼š{"call_function": {"name": "å‡½æ•°å", "args": {"å‚æ•°å": "å‚æ•°å€¼"}}}
        - å¦‚æœä¸éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œç›´æ¥è¾“å‡ºå›å¤å†…å®¹å³å¯
        - è°ƒç”¨å‡½æ•°æ—¶ï¼Œå‚æ•°å¿…é¡»ä¸¥æ ¼åŒ¹é…ä¸Šè¿°æ ¼å¼ï¼Œä¸è¦æ·»åŠ é¢å¤–å­—æ®µ
        """

    def _parse_function_call(self, model_response: str) -> dict:
        """è§£ææ¨¡å‹è¾“å‡ºçš„å‡½æ•°è°ƒç”¨æŒ‡ä»¤ï¼ˆæå–JSONï¼‰"""
        try:
            # æå–JSONéƒ¨åˆ†ï¼ˆå…¼å®¹æ¨¡å‹å¯èƒ½åŠ çš„é¢å¤–æ–‡å­—ï¼‰
            start = model_response.find("{")
            end = model_response.rfind("}") + 1
            json_str = model_response[start:end]
            call_data = json.loads(json_str)
            return call_data.get("call_function", {})
        except Exception as e:
            print(f"âš ï¸ è§£æå‡½æ•°è°ƒç”¨æŒ‡ä»¤å¤±è´¥: {e}")
            return {}

    def _execute_function(self, func_name: str, func_args: dict) -> str:
        """æ‰§è¡Œå‡½æ•°å¹¶è¿”å›ç»“æœ"""
        if func_name not in TOOL_MAP:
            return json.dumps({"error": f"å‡½æ•° {func_name} ä¸å­˜åœ¨"}, ensure_ascii=False)
        try:
            # è§£åŒ…å‚æ•°æ‰§è¡Œå‡½æ•°
            result = TOOL_MAP[func_name](**func_args)
            return result
        except Exception as e:
            return json.dumps({"error": f"æ‰§è¡Œ {func_name} å‡ºé”™: {str(e)}"}, ensure_ascii=False)

    def run(self, user_query: str):
        """è¿è¡ŒAgentï¼ˆæ— Schemaï¼Œçº¯Promptå¼•å¯¼ï¼‰"""
        print(f"ğŸ‘¤ ç”¨æˆ·æŒ‡ä»¤ï¼š{user_query}\n")

        # ç¬¬ä¸€æ­¥ï¼šå‘é€ç”¨æˆ·æŒ‡ä»¤ + å‡½æ•°è°ƒç”¨å¼•å¯¼Prompt
        initial_prompt = f"{self.function_call_prompt}\nç”¨æˆ·å½“å‰æŒ‡ä»¤ï¼š{user_query}"
        response = self.chat_session.send_message(initial_prompt)
        model_output = response.text.strip()

        # ç¬¬äºŒæ­¥ï¼šå¾ªç¯å¤„ç†æ¨¡å‹è¾“å‡ºï¼ˆæ”¯æŒå¤šè½®å‡½æ•°è°ƒç”¨ï¼‰
        while True:
            # è§£ææ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°
            func_call = self._parse_function_call(model_output)
            if not func_call:
                # æ¨¡å‹ç›´æ¥è¿”å›å›å¤ï¼Œç»“æŸæµç¨‹
                print(f"\nğŸ‰ æœ€ç»ˆå›å¤ï¼š\n{model_output}")
                break

            # æå–å‡½æ•°åå’Œå‚æ•°
            func_name = func_call.get("name")
            func_args = func_call.get("args", {})
            print(f"\nğŸ“Œ æ¨¡å‹å†³å®šè°ƒç”¨å‡½æ•°ï¼š{func_name}")
            print(f"ğŸ“Œ è°ƒç”¨å‚æ•°ï¼š{func_args}")

            # æ‰§è¡Œå‡½æ•°
            func_result = self._execute_function(func_name, func_args)
            print(f"âœ… å‡½æ•°æ‰§è¡Œç»“æœï¼š{func_result[:100]}...")

            # ç¬¬ä¸‰æ­¥ï¼šå°†å‡½æ•°ç»“æœå›ä¼ ç»™æ¨¡å‹ï¼Œç»§ç»­å†³ç­–
            follow_up_prompt = f"""
            ä½ ä¹‹å‰è°ƒç”¨äº†å‡½æ•° {func_name}ï¼Œå‚æ•°æ˜¯ {func_args}ï¼Œæ‰§è¡Œç»“æœå¦‚ä¸‹ï¼š
            {func_result}

            è¯·æ ¹æ®è¿™ä¸ªç»“æœå†³å®šï¼š
            1. ç»§ç»­è°ƒç”¨å…¶ä»–å‡½æ•°ï¼ˆæŒ‰æŒ‡å®šJSONæ ¼å¼è¾“å‡ºï¼‰ï¼›
            2. ç›´æ¥ç”Ÿæˆæœ€ç»ˆå›å¤ï¼ˆè¾“å‡ºæ–‡æœ¬å³å¯ï¼‰ã€‚
            """
            response = self.chat_session.send_message(follow_up_prompt)
            model_output = response.text.strip()


# ====================== è¿è¡Œæµ‹è¯• ======================
if __name__ == "__main__":
    # åˆå§‹åŒ–æ— Schemaçš„Agent
    agent = directorAgent()
    # è¿è¡Œæµ‹è¯•
    agent.run("ç»™æˆ‘æ€»ç»“è¿™å­¦æœŸå¤©æ–‡è¯¾ä¸Šçš„æ‰€æœ‰å†…å®¹")
