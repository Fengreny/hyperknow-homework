import json
import os
import time
from openai import OpenAI
from dotenv import load_dotenv

# ====================== 0. é…ç½®ä¸åˆå§‹åŒ– ======================
load_dotenv()

# é…ç½®ä»£ç†åœ°å€å’Œ Key
# âš ï¸ æ³¨æ„ï¼šè¿™é‡Œç”¨çš„æ˜¯ OpenAI çš„ SDKï¼Œä½†æ˜¯è°ƒç”¨çš„æ˜¯ Gemini æ¨¡å‹
client = OpenAI(
    api_key= os.getenv("GPTS_API_KEY"),  # å¡«å…¥ä½ åœ¨ gptsapi çš„ key
    base_url="https://api.gptsapi.net/v1"  # ä»£ç†åœ°å€
)

MODEL_NAME = "gemini-3-pro-preview"  # æˆ–è€… gemini-1.5-pro


# ====================== 1. å®šä¹‰å·¥å…·å‡½æ•° ======================

def memory_load_function(subject: str):
    """
    è¯»å–memory.jsonï¼ŒæŸ¥è¯¢ç”¨æˆ·æŒ‡å®šç§‘ç›®çš„çŸ¥è¯†æ°´å¹³ã€‚
    """
    print(f"\nğŸ” [Tool] æ­£åœ¨æŸ¥è¯¢è®°å¿†åº“: {subject}")
    try:
        # ç¡®ä¿ä½ æœ‰ memory.json
        with open('memory.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        knowledge_levels = data.get("knowledge_levels", {})
        if subject.lower() in knowledge_levels:
            return json.dumps(knowledge_levels[subject.lower()])  # è¿”å›å­—ç¬¦ä¸²
        else:
            return json.dumps({"error": f"æœªæ‰¾åˆ° {subject} çš„è®°å¿†ä¿¡æ¯"})
    except Exception as e:
        return json.dumps({"error": f"è¯»å–è®°å¿†æ–‡ä»¶å‡ºé”™: {str(e)}"})


def select_files(query: str):
    """
    æ ¹æ®å…³é”®è¯æœç´¢æœ¬åœ°æ–‡ä»¶ï¼Œè¿”å›ç›¸å…³æ–‡ä»¶ååˆ—è¡¨ã€‚
    """
    print(f"\nğŸ“‚ [Tool] æ­£åœ¨æœç´¢æ–‡ä»¶å…³é”®è¯: {query}")
    found_files = []
    try:
        # ç¡®ä¿ä½ æœ‰ file_metadata.json
        with open('file_metadata.json', 'r', encoding='utf-8') as f:
            file_data = json.load(f)
        for filename, info in file_data.items():
            content = info.get("content", "").lower()
            if query.lower() in content:
                found_files.append(filename)
        print(f"   âœ… æ‰¾åˆ° {len(found_files)} ä¸ªç›¸å…³æ–‡ä»¶")
        return json.dumps(found_files)
    except Exception as e:
        return json.dumps({"error": f"æœç´¢æ–‡ä»¶å‡ºé”™: {str(e)}"})


def reply_generator(file_titles_json: str, instruction: str):
    """
    ç”Ÿæˆæœ€ç»ˆå›å¤ã€‚
    æ³¨æ„ï¼šOpenAI Function Calling ä¼ å›æ¥çš„æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è‡ªå·± json.loads ä¸€ä¸‹ file_titles
    """
    try:
        file_titles = json.loads(file_titles_json)
    except:
        file_titles = []  # å®¹é”™

    print(f"\nğŸ“ [Tool] æ­£åœ¨è°ƒç”¨å›å¤ç”Ÿæˆå™¨...")
    print(f"   å‚è€ƒæ–‡ä»¶: {file_titles}")

    context_content = ""
    try:
        with open('file_metadata.json', 'r', encoding='utf-8') as f:
            all_files_data = json.load(f)
        for title in file_titles:
            if title in all_files_data:
                file_text = all_files_data[title]['content']
                context_content += f"\n--- æ–‡ä»¶å: {title} ---\n{file_text}\n"
    except Exception as e:
        return f"è¯»å–æ–‡ä»¶å†…å®¹å‡ºé”™: {str(e)}"

    final_prompt = f"""
    ã€è§’è‰²ã€‘å¤©æ–‡è¯¾åŠ©æ•™
    ã€ç”¨æˆ·æŒ‡ä»¤ã€‘{instruction}
    ã€å‚è€ƒèµ„æ–™ã€‘{context_content if context_content else "æ— "}
    ã€è¦æ±‚ã€‘è¯·æ ¹æ®å‚è€ƒèµ„æ–™å’ŒæŒ‡ä»¤ï¼Œç”Ÿæˆè¯¦ç»†çš„æ€»ç»“ã€‚
    """

    print("\nğŸ’¡ [Stream] å¼€å§‹æµå¼è¾“å‡ºå›å¤: \n")

    # ä½¿ç”¨ client.chat.completions.create è¿›è¡Œæµå¼ç”Ÿæˆ
    stream = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": final_prompt}],
        stream=True
    )

    full_text = ""
    for chunk in stream:
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            print(content, end="", flush=True)
            full_text += content
    print("\n")

    return "å›å¤å·²ç”Ÿæˆå®Œæ¯•ã€‚"


# ====================== 2. å®šä¹‰ Tools Schema (OpenAI æ ¼å¼) ======================
# OpenAI éœ€è¦æ˜¾å¼å®šä¹‰ Schemaï¼Œä¸åƒ Gemini SDK é‚£ä¹ˆæ™ºèƒ½è‡ªåŠ¨ç”Ÿæˆ
tools = [
    {
        "type": "function",
        "function": {
            "name": "memory_load_function",
            "description": "è¯»å–memory.jsonï¼ŒæŸ¥è¯¢ç”¨æˆ·æŒ‡å®šç§‘ç›®çš„çŸ¥è¯†æ°´å¹³ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "subject": {
                        "type": "string",
                        "description": "ç§‘ç›®åç§°ï¼Œä¾‹å¦‚ 'astronomy', 'calculus' ç­‰ã€‚"
                    }
                },
                "required": ["subject"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "select_files",
            "description": "æ ¹æ®å…³é”®è¯æœç´¢æœ¬åœ°æ–‡ä»¶ï¼Œè¿”å›ç›¸å…³æ–‡ä»¶ååˆ—è¡¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ 'astronomy'ã€‚"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "reply_generator",
            "description": "è¿™æ˜¯ç”Ÿæˆæœ€ç»ˆå›å¤çš„å”¯ä¸€å·¥å…·ã€‚æ ¹æ®æä¾›çš„æ–‡ä»¶åˆ—è¡¨å’ŒæŒ‡ä»¤ï¼Œæµå¼ç”Ÿæˆå›ç­”ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_titles_json": {
                        "type": "string",
                        "description": "éœ€è¦å‚è€ƒçš„æ–‡ä»¶ååˆ—è¡¨ï¼Œå¿…é¡»æ˜¯ JSON å­—ç¬¦ä¸²æ ¼å¼ï¼Œä¾‹å¦‚ '[\"file1.pdf\", \"file2.pdf\"]'ã€‚"
                    },
                    "instruction": {
                        "type": "string",
                        "description": "ç”Ÿæˆå›å¤çš„å…·ä½“æŒ‡ä»¤ã€‚"
                    }
                },
                "required": ["file_titles_json", "instruction"]
            }
        }
    }
]

available_functions = {
    "memory_load_function": memory_load_function,
    "select_files": select_files,
    "reply_generator": reply_generator,
}


# ====================== 3. æ ¸å¿ƒ Agent é€»è¾‘ ======================
class HyperknowAgent:
    def __init__(self):
        self.messages = []  # æ‰‹åŠ¨ç»´æŠ¤å†å²è®°å½•

    def run(self, user_query: str):
        print(f"ğŸ‘¤ ç”¨æˆ·æŒ‡ä»¤ï¼š{user_query}")
        self.messages.append({"role": "user", "content": user_query})

        while True:
            # 1. å‘é€è¯·æ±‚ç»™æ¨¡å‹
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=self.messages,
                tools=tools,
                tool_choice="auto"
            )

            response_message = response.choices[0].message

            # 2. æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
            tool_calls = response_message.tool_calls

            if tool_calls:
                # æŠŠæ¨¡å‹çš„å›å¤ï¼ˆåŒ…å«å‡½æ•°è°ƒç”¨è¯·æ±‚ï¼‰åŠ å…¥å†å²
                self.messages.append(response_message)

                for tool_call in tool_calls:
                    function_name = tool_call.function.name
                    function_to_call = available_functions[function_name]
                    function_args = json.loads(tool_call.function.arguments)

                    print(f"\nğŸ¤– æ¨¡å‹è¯·æ±‚è°ƒç”¨: {function_name}")
                    print(f"   å‚æ•°: {function_args}")

                    # 3. æ‰§è¡Œå‡½æ•°
                    function_response = function_to_call(**function_args)

                    # 4. å°†ç»“æœå›ä¼ ç»™æ¨¡å‹
                    print(f"   ğŸ“¤ å°†ç»“æœå›ä¼ ç»™ Director Agent...")
                    self.messages.append(
                        {
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": function_response,
                        }
                    )
            else:
                # æ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œè¯´æ˜ä»»åŠ¡ç»“æŸ
                print(f"\nğŸ‰ Director Agent ä»»åŠ¡ç»“æŸ: {response_message.content}")
                break


# ====================== è¿è¡Œæµ‹è¯• ======================
if __name__ == "__main__":
    # ç¡®ä¿ç›®å½•ä¸‹æœ‰ memory.json å’Œ file_metadata.json
    agent = HyperknowAgent()
    agent.run("ç»™æˆ‘æ€»ç»“è¿™å­¦æœŸå¤©æ–‡è¯¾ä¸Šçš„æ‰€æœ‰å†…å®¹")
